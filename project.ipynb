{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOBmhxqxWVOrUVoqNOA+nm8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhagyapatel/Big-Data/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2riY_DfUoKO"
      },
      "outputs": [],
      "source": [
        " !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        " !wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        " !tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        " !pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "os.environ[\"path\"] =\"${SPARK_HOME}/bin\"\n",
        "#spark-submit = /content/spark-3.0.0-bin-hadoop3.2/bin/spark-submit"
      ],
      "metadata": {
        "id": "_UgoHd_Hehhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "33fwyW9UeheK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Project\").getOrCreate()\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "PRUdAeg6eha_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/azar-s91/dataset/master/weatherHistory.csv\""
      ],
      "metadata": {
        "id": "t3NqRX4xeg20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles,SparkContext"
      ],
      "metadata": {
        "id": "CseDKyZDmLkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.addFile(url)  "
      ],
      "metadata": {
        "id": "YagSMmNemVIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\",True).csv(\"file://\" +SparkFiles.get(\"weatherHistory.csv\"))"
      ],
      "metadata": {
        "id": "JbWjnenwegpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bze6bnOUjV3r",
        "outputId": "6cfbc53a-52e8-43a9-a6fe-66a0f2f03132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---------------+--------+-----------------+--------------------+-------------+\n",
            "|       DateTime|Temperature (C)|Humidity|Wind Speed (km/h)|Pressure (millibars)|      Summary|\n",
            "+---------------+---------------+--------+-----------------+--------------------+-------------+\n",
            "|4/1/06 12:00 AM|    9.472222222|    0.89|          14.1197|             1015.13|Partly Cloudy|\n",
            "| 4/1/06 1:00 AM|    9.355555556|    0.86|          14.2646|             1015.63|Partly Cloudy|\n",
            "| 4/1/06 2:00 AM|    9.377777778|    0.89|           3.9284|             1015.94|Mostly Cloudy|\n",
            "| 4/1/06 3:00 AM|    8.288888889|    0.83|          14.1036|                null|Partly Cloudy|\n",
            "| 4/1/06 4:00 AM|    8.755555556|    0.83|          11.0446|             1016.51|Mostly Cloudy|\n",
            "| 4/1/06 5:00 AM|    9.222222222|    0.85|          13.9587|             1016.66|Partly Cloudy|\n",
            "| 4/1/06 6:00 AM|    7.733333333|    0.95|          12.3648|             1016.72|Partly Cloudy|\n",
            "| 4/1/06 7:00 AM|    8.772222222|    0.89|          14.1519|             1016.84|Partly Cloudy|\n",
            "| 4/1/06 8:00 AM|    10.82222222|    0.82|          11.3183|             1017.37|Partly Cloudy|\n",
            "| 4/1/06 9:00 AM|    13.77222222|    0.72|          12.5258|             1017.22|Partly Cloudy|\n",
            "|4/1/06 10:00 AM|    16.01666667|    0.67|          17.5651|             1017.42|Partly Cloudy|\n",
            "|4/1/06 11:00 AM|    17.14444444|    0.54|          19.7869|             1017.74|Partly Cloudy|\n",
            "|4/1/06 12:00 PM|           null|    0.55|          21.9443|             1017.59|Partly Cloudy|\n",
            "| 4/1/06 1:00 PM|    17.33333333|    0.51|          20.6885|             1017.48|Partly Cloudy|\n",
            "| 4/1/06 2:00 PM|    18.87777778|    0.47|          15.3755|             1017.17|Partly Cloudy|\n",
            "| 4/1/06 3:00 PM|    18.91111111|    0.46|          10.4006|             1016.47|Partly Cloudy|\n",
            "| 4/1/06 4:00 PM|    15.38888889|     0.6|          14.4095|             1016.15|Partly Cloudy|\n",
            "| 4/1/06 5:00 PM|          15.55|    0.63|             null|             1016.17|Mostly Cloudy|\n",
            "| 4/1/06 6:00 PM|    14.25555556|    0.69|           8.5169|             1015.82|Mostly Cloudy|\n",
            "| 4/1/06 7:00 PM|    13.14444444|     0.7|           7.6314|             1015.83|Mostly Cloudy|\n",
            "+---------------+---------------+--------+-----------------+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
        "df.withColumn(\"new_Date1\", to_date(\"DateTime\",\"MM/dd/yy\")).show()"
      ],
      "metadata": {
        "id": "EsMdwEW4HwaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "aS-DaW8krAq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed(\"Temperature (C)\", \"temp\").withColumnRenamed(\"Wind Speed (km/h)\",\"wind_speed\") \\\n",
        ".withColumnRenamed(\"Pressure (millibars)\",\"pressure\")"
      ],
      "metadata": {
        "id": "HZPlPIASA6vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select([count(when(isnull(c), c)).alias(c) for c in df.columns]).show()"
      ],
      "metadata": {
        "id": "4PSzWtuQ4sZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f739fce7-eb11-4502-d57e-2f8dce981488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----+--------+----------+--------+-------+\n",
            "|DateTime|temp|Humidity|wind_speed|pressure|Summary|\n",
            "+--------+----+--------+----------+--------+-------+\n",
            "|       0|  11|       8|         9|       7|      0|\n",
            "+--------+----+--------+----------+--------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.partitionBy(\"Summary\").mode(\"overWrite\").option(\"maxRecordPerPartition\",2).csv(\"/content/sample_data/spark_df\")"
      ],
      "metadata": {
        "id": "FRhfSqWB50o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.partitionBy(\"Summary\").mode(\"overwrite\").format(\"csv\").option(\"maxRecordPerPartition\",2).saveAsTable(\"hive_df\")"
      ],
      "metadata": {
        "id": "TeihvRpuAoJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"show databases\").show()"
      ],
      "metadata": {
        "id": "JYlK8VmDzULO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af849170-5f8a-4dff-c6ee-beeaff9cc7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|namespace|\n",
            "+---------+\n",
            "|  default|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"show partitions hive_df\").show()"
      ],
      "metadata": {
        "id": "UhKebQVt2RFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"show tables\").show()"
      ],
      "metadata": {
        "id": "vuhtHby_zihy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from hive_df\").show()"
      ],
      "metadata": {
        "id": "g2BvU7bgzw6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_valid = df.filter(\"'DateTime' is not null and \\\n",
        " 'Temperature (C)' is not null and \\\n",
        " 'Humidity' is not null and \\\n",
        "  'Wind Speed (km/h)' is not null and \\\n",
        "  'Pressure (millibars)' is not null\")"
      ],
      "metadata": {
        "id": "yYZ_rMvL1qQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_invalid = df.filter(\"'DateTime' is null or \\\n",
        " 'Temperature (C)' is null or \\\n",
        " 'Humidity' is null or \\\n",
        "  'Wind Speed (km/h)' is null or \\\n",
        "  'Pressure (millibars)' is null\")"
      ],
      "metadata": {
        "id": "cDyrhN96D0iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_invalid.write.option(\"header\",True).mode(\"overwrite\").saveAsTable(\"invalid_df\")"
      ],
      "metadata": {
        "id": "4E5qGv5eEC8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_valid.write.option(\"header\",True).mode(\"overwrite\").saveAsTable(\"valid_df\")"
      ],
      "metadata": {
        "id": "gpnNjYDnuMtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")"
      ],
      "metadata": {
        "id": "B6PUWtSL4KYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff = df.withColumn(\"date1\", to_date(\n",
        "    from_unixtime(\n",
        "        unix_timestamp(\"DateTime\", \"MM/dd/yy hh:mm a\")).cast(TimestampType()))).show()"
      ],
      "metadata": {
        "id": "FHZCqS6q2v9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563c71c6-f664-4c2c-a482-f4a9694b5180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----------+--------+----------+--------+-------------+----------+\n",
            "|       DateTime|       temp|Humidity|wind_speed|pressure|      Summary|     date1|\n",
            "+---------------+-----------+--------+----------+--------+-------------+----------+\n",
            "|4/1/06 12:00 AM|9.472222222|    0.89|   14.1197| 1015.13|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 1:00 AM|9.355555556|    0.86|   14.2646| 1015.63|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 2:00 AM|9.377777778|    0.89|    3.9284| 1015.94|Mostly Cloudy|2006-04-01|\n",
            "| 4/1/06 3:00 AM|8.288888889|    0.83|   14.1036|    null|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 4:00 AM|8.755555556|    0.83|   11.0446| 1016.51|Mostly Cloudy|2006-04-01|\n",
            "| 4/1/06 5:00 AM|9.222222222|    0.85|   13.9587| 1016.66|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 6:00 AM|7.733333333|    0.95|   12.3648| 1016.72|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 7:00 AM|8.772222222|    0.89|   14.1519| 1016.84|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 8:00 AM|10.82222222|    0.82|   11.3183| 1017.37|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 9:00 AM|13.77222222|    0.72|   12.5258| 1017.22|Partly Cloudy|2006-04-01|\n",
            "|4/1/06 10:00 AM|16.01666667|    0.67|   17.5651| 1017.42|Partly Cloudy|2006-04-01|\n",
            "|4/1/06 11:00 AM|17.14444444|    0.54|   19.7869| 1017.74|Partly Cloudy|2006-04-01|\n",
            "|4/1/06 12:00 PM|       null|    0.55|   21.9443| 1017.59|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 1:00 PM|17.33333333|    0.51|   20.6885| 1017.48|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 2:00 PM|18.87777778|    0.47|   15.3755| 1017.17|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 3:00 PM|18.91111111|    0.46|   10.4006| 1016.47|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 4:00 PM|15.38888889|     0.6|   14.4095| 1016.15|Partly Cloudy|2006-04-01|\n",
            "| 4/1/06 5:00 PM|      15.55|    0.63|      null| 1016.17|Mostly Cloudy|2006-04-01|\n",
            "| 4/1/06 6:00 PM|14.25555556|    0.69|    8.5169| 1015.82|Mostly Cloudy|2006-04-01|\n",
            "| 4/1/06 7:00 PM|13.14444444|     0.7|    7.6314| 1015.83|Mostly Cloudy|2006-04-01|\n",
            "+---------------+-----------+--------+----------+--------+-------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df.withColumn(\"date1\", to_date(current_timestamp())).show(1)\n",
        "df1 = df.withColumn(\"DateOnly\", \n",
        "                    to_date(\n",
        "                        from_unixtime(\n",
        "                            unix_timestamp(\"DateTime\",\"MM/dd/yy hh:mm a\")\n",
        "                        ).cast(TimestampType())\n",
        "                        )\n",
        "                    )\n",
        "                    "
      ],
      "metadata": {
        "id": "zOaYM2V_68fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.write.option(\"header\",True)\\\n",
        ".mode(\"overwrite\")\\\n",
        ".csv(\"df5\")"
      ],
      "metadata": {
        "id": "eBHifgbmIvWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.withColumn(\"DateOnly\", date_format(\"DateOnly\",\"MM/dd/yyyy\")).show()\n",
        "df1.show()"
      ],
      "metadata": {
        "id": "9p9xZx4uv_G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.withColumn(\"DateTime1\",to_timestamp(\"DateTime\",\"MM/dd/yy hh:mm\"))\n",
        "df1.show()"
      ],
      "metadata": {
        "id": "dyMjyvL11-hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df1.withColumn(\"year\",year(\"DateOnly\")).show()\n",
        "#df1.withColumn(\"month\",month(\"DateOnly\")).show()\n",
        "#df1.withColumn(\"date_diff1\",datediff(current_date(),\"DateOnly\")).show()\n",
        "#df1.withColumn(\"day\",dayofmonth(\"DateOnly\")).show()\n",
        "#df1.withColumn(\"hour1\", hour(\"DateTime1\")).show()\n",
        "#df1.withColumn(\"week_of_year\", weekofyear(\"DateTime1\")).show() \n",
        "#df1.withColumn(\"dayinwords\", date_format(\"DateOnly\",\"EEE\")).show()\n",
        "#df1.withColumn(\"monthinwords\", date_format(\"DateOnly\",\"LLL\")).show()\n",
        "#df1.withColumn(\"new_Date\", add_months(\"DateOnly\",3)).show()\n",
        "df1.withColumn(\"new_Date\", date_add(\"DateOnly\",3)).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZQo8pIQxDp7",
        "outputId": "920774c6-d0db-4dba-fc5d-a7467fb8b035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----------+--------+----------+--------+-------------+----------+-------------------+----------+\n",
            "|       DateTime|       temp|Humidity|wind_speed|pressure|      Summary|  DateOnly|          DateTime1|  new_Date|\n",
            "+---------------+-----------+--------+----------+--------+-------------+----------+-------------------+----------+\n",
            "|4/1/06 12:00 AM|9.472222222|    0.89|   14.1197| 1015.13|Partly Cloudy|2006-04-01|2006-04-01 00:00:00|2006-04-04|\n",
            "| 4/1/06 1:00 AM|9.355555556|    0.86|   14.2646| 1015.63|Partly Cloudy|2006-04-01|2006-04-01 01:00:00|2006-04-04|\n",
            "| 4/1/06 2:00 AM|9.377777778|    0.89|    3.9284| 1015.94|Mostly Cloudy|2006-04-01|2006-04-01 02:00:00|2006-04-04|\n",
            "| 4/1/06 3:00 AM|8.288888889|    0.83|   14.1036|    null|Partly Cloudy|2006-04-01|2006-04-01 03:00:00|2006-04-04|\n",
            "| 4/1/06 4:00 AM|8.755555556|    0.83|   11.0446| 1016.51|Mostly Cloudy|2006-04-01|2006-04-01 04:00:00|2006-04-04|\n",
            "| 4/1/06 5:00 AM|9.222222222|    0.85|   13.9587| 1016.66|Partly Cloudy|2006-04-01|2006-04-01 05:00:00|2006-04-04|\n",
            "| 4/1/06 6:00 AM|7.733333333|    0.95|   12.3648| 1016.72|Partly Cloudy|2006-04-01|2006-04-01 06:00:00|2006-04-04|\n",
            "| 4/1/06 7:00 AM|8.772222222|    0.89|   14.1519| 1016.84|Partly Cloudy|2006-04-01|2006-04-01 07:00:00|2006-04-04|\n",
            "| 4/1/06 8:00 AM|10.82222222|    0.82|   11.3183| 1017.37|Partly Cloudy|2006-04-01|2006-04-01 08:00:00|2006-04-04|\n",
            "| 4/1/06 9:00 AM|13.77222222|    0.72|   12.5258| 1017.22|Partly Cloudy|2006-04-01|2006-04-01 09:00:00|2006-04-04|\n",
            "|4/1/06 10:00 AM|16.01666667|    0.67|   17.5651| 1017.42|Partly Cloudy|2006-04-01|2006-04-01 10:00:00|2006-04-04|\n",
            "|4/1/06 11:00 AM|17.14444444|    0.54|   19.7869| 1017.74|Partly Cloudy|2006-04-01|2006-04-01 11:00:00|2006-04-04|\n",
            "|4/1/06 12:00 PM|       null|    0.55|   21.9443| 1017.59|Partly Cloudy|2006-04-01|2006-04-01 00:00:00|2006-04-04|\n",
            "| 4/1/06 1:00 PM|17.33333333|    0.51|   20.6885| 1017.48|Partly Cloudy|2006-04-01|2006-04-01 01:00:00|2006-04-04|\n",
            "| 4/1/06 2:00 PM|18.87777778|    0.47|   15.3755| 1017.17|Partly Cloudy|2006-04-01|2006-04-01 02:00:00|2006-04-04|\n",
            "| 4/1/06 3:00 PM|18.91111111|    0.46|   10.4006| 1016.47|Partly Cloudy|2006-04-01|2006-04-01 03:00:00|2006-04-04|\n",
            "| 4/1/06 4:00 PM|15.38888889|     0.6|   14.4095| 1016.15|Partly Cloudy|2006-04-01|2006-04-01 04:00:00|2006-04-04|\n",
            "| 4/1/06 5:00 PM|      15.55|    0.63|      null| 1016.17|Mostly Cloudy|2006-04-01|2006-04-01 05:00:00|2006-04-04|\n",
            "| 4/1/06 6:00 PM|14.25555556|    0.69|    8.5169| 1015.82|Mostly Cloudy|2006-04-01|2006-04-01 06:00:00|2006-04-04|\n",
            "| 4/1/06 7:00 PM|13.14444444|     0.7|    7.6314| 1015.83|Mostly Cloudy|2006-04-01|2006-04-01 07:00:00|2006-04-04|\n",
            "+---------------+-----------+--------+----------+--------+-------------+----------+-------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD1aZFjaHHEs",
        "outputId": "976f3c72-30ed-4c01-c017-c908515da8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df5\t     spark-3.0.0-bin-hadoop3.2\t    spark-warehouse\n",
            "sample_data  spark-3.0.0-bin-hadoop3.2.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hadoop fs -cat /content/test2.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mONx74PGR6yi",
        "outputId": "01e35380-733b-48af-d88c-c3c7d265cecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: hadoop: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df.withColumn(\"date1\", to_date(\"DateTime\",\"MM/dd/yy hh:mm a\")).show(1)"
      ],
      "metadata": {
        "id": "ncFOUEcnBv2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import JSON\n",
        "from google.colab import output\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "def shell(command):\n",
        "  if command.startswith('cd'):\n",
        "    path = command.strip().split(maxsplit=1)[1]\n",
        "    os.chdir(path)\n",
        "    return JSON([''])\n",
        "  return JSON([getoutput(command)])\n",
        "output.register_callback('shell', shell)"
      ],
      "metadata": {
        "id": "27Nb0BiMIPN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Colab Shell\n",
        "%%html\n",
        "<div id=term_demo></div>\n",
        "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
        "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
        "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
        "<script>\n",
        "  $('#term_demo').terminal(async function(command) {\n",
        "      if (command !== '') {\n",
        "          try {\n",
        "              let res = await google.colab.kernel.invokeFunction('shell', [command])\n",
        "              let out = res.data['application/json'][0]\n",
        "              this.echo(new String(out))\n",
        "          } catch(e) {\n",
        "              this.error(new String(e));\n",
        "          }\n",
        "      } else {\n",
        "          this.echo('');\n",
        "      }\n",
        "  }, {\n",
        "      greetings: 'Welcome to Colab Shell',\n",
        "      name: 'colab_demo',\n",
        "      height: 250,\n",
        "      prompt: 'colab > '\n",
        "  });"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "Do8tZGzuLI-S",
        "outputId": "fc7e8ec8-05b0-43ed-ed50-4b826a875688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=term_demo></div>\n",
              "<script src=\"https://code.jquery.com/jquery-latest.js\"></script>\n",
              "<script src=\"https://cdn.jsdelivr.net/npm/jquery.terminal/js/jquery.terminal.min.js\"></script>\n",
              "<link href=\"https://cdn.jsdelivr.net/npm/jquery.terminal/css/jquery.terminal.min.css\" rel=\"stylesheet\"/>\n",
              "<script>\n",
              "  $('#term_demo').terminal(async function(command) {\n",
              "      if (command !== '') {\n",
              "          try {\n",
              "              let res = await google.colab.kernel.invokeFunction('shell', [command])\n",
              "              let out = res.data['application/json'][0]\n",
              "              this.echo(new String(out))\n",
              "          } catch(e) {\n",
              "              this.error(new String(e));\n",
              "          }\n",
              "      } else {\n",
              "          this.echo('');\n",
              "      }\n",
              "  }, {\n",
              "      greetings: 'Welcome to Colab Shell',\n",
              "      name: 'colab_demo',\n",
              "      height: 250,\n",
              "      prompt: 'colab > '\n",
              "  });\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOh57f0zegWQ",
        "outputId": "6f2582db-f80e-418e-fd81-c7bac89391ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "project.py   spark-3.0.0-bin-hadoop3.2\t    untitled14.py\n",
            "sample_data  spark-3.0.0-bin-hadoop3.2.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!spark-submit --master local untitled14.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifxik7ENeiZg",
        "outputId": "dca50c78-6364-480e-a7cb-c0835e75fad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: spark-submit: command not found\n"
          ]
        }
      ]
    }
  ]
}