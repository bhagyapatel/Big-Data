{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP789FFVEhpjo9MO4Juwwj1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhagyapatel/Big-Data/blob/main/Date_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBMaeD0ffIgX"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n"
      ],
      "metadata": {
        "id": "9UufKi_rh0Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "8zsEnWOsi1Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "b6_GMhWGi_CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[[\"1\",\"2020-02-01\"],[\"2\",\"2019-03-01\"],[\"3\",\"2021-03-01\"]]\n",
        "df = spark.createDataFrame(data,[\"id\",\"date1\"])\n",
        "df.show()\n",
        "from pyspark.sql.functions import *\n",
        "df.select(current_date()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-83CyHyojzqp",
        "outputId": "cbb857a5-fef6-4d88-ce62-a53b68f755c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+\n",
            "| id|     date1|\n",
            "+---+----------+\n",
            "|  1|2020-02-01|\n",
            "|  2|2019-03-01|\n",
            "|  3|2021-03-01|\n",
            "+---+----------+\n",
            "\n",
            "+--------------+\n",
            "|current_date()|\n",
            "+--------------+\n",
            "|    2022-10-29|\n",
            "|    2022-10-29|\n",
            "|    2022-10-29|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"date1\",date_format(\"date1\",\"dd-MM-yyyy\").alias(\"new_date\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8AAcVU1kgCs",
        "outputId": "94fb3f43-7f8e-408a-c78b-e0523df84b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|     date1|  new_date|\n",
            "+----------+----------+\n",
            "|2020-02-01|01-02-2020|\n",
            "|2019-03-01|01-03-2019|\n",
            "|2021-03-01|01-03-2021|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"date1\", to_date(\"date1\",\"yyyy-MM-dd\").alias(\"format_Date\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuJVcqdXlvWX",
        "outputId": "0e713e18-b920-457b-930a-67cc8f41d5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|     date1|format_Date|\n",
            "+----------+-----------+\n",
            "|2020-02-01| 2020-02-01|\n",
            "|2019-03-01| 2019-03-01|\n",
            "|2021-03-01| 2021-03-01|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"date1\", current_date().alias(\"current_date\"), datediff(current_date(),\"date1\").alias(\"difference\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPhJ_XmImSaf",
        "outputId": "bf71adc2-5a2a-4f71-bbd2-2789066e3333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+----------+\n",
            "|     date1|current_date|difference|\n",
            "+----------+------------+----------+\n",
            "|2020-02-01|  2022-10-29|      1001|\n",
            "|2019-03-01|  2022-10-29|      1338|\n",
            "|2021-03-01|  2022-10-29|       607|\n",
            "+----------+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"date1\", year(\"date1\"),month(\"date1\"),date).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2xcLmT7nT_B",
        "outputId": "9ea3a7c8-2184-4c8f-9837-5c7d242d8087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|     date1|year(date1)|\n",
            "+----------+-----------+\n",
            "|2020-02-01|       2020|\n",
            "|2019-03-01|       2019|\n",
            "|2021-03-01|       2021|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"date1\", add_months(\"date1\",3)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xwSSKIgpHBe",
        "outputId": "3277fb3e-ee05-4b4b-b2d8-00f1a1f17719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|     date1|add_months(date1, 3)|\n",
            "+----------+--------------------+\n",
            "|2020-02-01|          2020-05-01|\n",
            "|2019-03-01|          2019-06-01|\n",
            "|2021-03-01|          2021-06-01|\n",
            "+----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df.withColumn(\"year\",year(\"date1\")).show()\n",
        "#df.withColumn(\"month\",month(\"date1\")).show()\n",
        "#df.withColumn(\"date_diff1\",datediff(current_date(),\"date1\")).show()\n",
        "#df1.withColumn(\"day\",dayofmonth(\"date1\")).show()\n",
        "#df1.withColumn(\"hour1\", hour(\"DateTime1\")).show()\n",
        "#df.withColumn(\"week_of_year\", weekofyear(\"date1\")).show() \n",
        "#df.withColumn(\"dayinwords\", date_format(\"date1\",\"EEE\")).show()\n",
        "#df.withColumn(\"monthinwords\", date_format(\"date1\",\"LLL\")).show()\n",
        "#df.withColumn(\"new_Date\", add_months(\"date1\",3)).show()\n",
        "df.withColumn(\"new_Date\", date_add(\"date1\",3)).show()"
      ],
      "metadata": {
        "id": "0pkGpUqMGLEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"date1\", add_months(\"date1\",3), date_add(\"date1\",3), date_add(\"date1\",-3), date_sub(\"date1\",3)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHPsmkzbp-82",
        "outputId": "b08730bc-c890-421c-c421-c535f6138b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+------------------+-------------------+------------------+\n",
            "|     date1|add_months(date1, 3)|date_add(date1, 3)|date_add(date1, -3)|date_sub(date1, 3)|\n",
            "+----------+--------------------+------------------+-------------------+------------------+\n",
            "|2020-02-01|          2020-05-01|        2020-02-04|         2020-01-29|        2020-01-29|\n",
            "|2019-03-01|          2019-06-01|        2019-03-04|         2019-02-26|        2019-02-26|\n",
            "|2021-03-01|          2021-06-01|        2021-03-04|         2021-02-26|        2021-02-26|\n",
            "+----------+--------------------+------------------+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(col(\"date1\"),  \n",
        "     dayofweek(col(\"date1\")).alias(\"dayofweek\"), \n",
        "     dayofmonth(col(\"date1\")).alias(\"dayofmonth\"), \n",
        "     dayofyear(col(\"date1\")).alias(\"dayofyear\"), \n",
        "  ).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MBppRTLqwz3",
        "outputId": "314e427d-f806-46aa-c559-8770da5f7d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+----------+---------+\n",
            "|     date1|dayofweek|dayofmonth|dayofyear|\n",
            "+----------+---------+----------+---------+\n",
            "|2020-02-01|        7|         1|       32|\n",
            "|2019-03-01|        6|         1|       60|\n",
            "|2021-03-01|        2|         1|       60|\n",
            "+----------+---------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[[\"1\",\"02-01-2020 11 01 19 06\"],[\"2\",\"03-01-2019 12 01 19 406\"],[\"3\",\"03-01-2021 12 01 19 406\"]]\n",
        "df2=spark.createDataFrame(data,[\"id\",\"input\"])\n",
        "df2.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz8VHx0AqxhM",
        "outputId": "9f127531-cd00-4a4d-b05a-17fc606c263b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------------+\n",
            "|id |input                  |\n",
            "+---+-----------------------+\n",
            "|1  |02-01-2020 11 01 19 06 |\n",
            "|2  |03-01-2019 12 01 19 406|\n",
            "|3  |03-01-2021 12 01 19 406|\n",
            "+---+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df2.select(current_timestamp().alias(\"current_timestamp\")\n",
        "  ).show(1,truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2b9-_poq2J_",
        "outputId": "494bb1ba-1ee8-44f0-955d-d31e618fdb92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+\n",
            "|current_timestamp      |\n",
            "+-----------------------+\n",
            "|2022-10-29 12:21:19.524|\n",
            "+-----------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hour, minute,second\n",
        "data=[[\"1\",\"2020-02-01 11:01:19.06\"],[\"2\",\"2019-03-01 12:01:19.406\"],[\"3\",\"2021-03-01 12:01:19.406\"]]\n",
        "df3=spark.createDataFrame(data,[\"id\",\"input\"])\n",
        "df3.select(col(\"input\"), \n",
        "    hour(col(\"input\")).alias(\"hour\"), \n",
        "    minute(col(\"input\")).alias(\"minute\"),\n",
        "    second(col(\"input\")).alias(\"second\") \n",
        "  ).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k59x7Umyq4le",
        "outputId": "16bbdebe-7485-4ec0-de5f-54c6afb4275a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+----+------+------+\n",
            "|input                  |hour|minute|second|\n",
            "+-----------------------+----+------+------+\n",
            "|2020-02-01 11:01:19.06 |11  |1     |19    |\n",
            "|2019-03-01 12:01:19.406|12  |1     |19    |\n",
            "|2021-03-01 12:01:19.406|12  |1     |19    |\n",
            "+-----------------------+----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "#Split one column into multiple columns\n",
        "park=SparkSession.builder.appName(\"sparkbyexamples\").getOrCreate()\n",
        "data= [('James','','Smith','1991-04-01'),\n",
        "  ('Michael','Rose','','2000-05-19'),\n",
        "  ('Robert','','Williams','1978-09-05'),\n",
        "  ('Maria','Anne','Jones','1967-12-01'),\n",
        "  ('Jen','Mary','Brown','1980-02-17')\n",
        "]"
      ],
      "metadata": {
        "id": "nlGF5-nGa63U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Columns = [\"name\",\"middlename\",\"lastname\",\"dob\"]\n",
        "df = spark.createDataFrame(data,Columns)\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeNOiEwEl_88",
        "outputId": "b952ae80-0d8b-42e6-d938-00d3ad97e107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+--------+----------+\n",
            "|   name|middlename|lastname|       dob|\n",
            "+-------+----------+--------+----------+\n",
            "|  James|          |   Smith|1991-04-01|\n",
            "|Michael|      Rose|        |2000-05-19|\n",
            "| Robert|          |Williams|1978-09-05|\n",
            "|  Maria|      Anne|   Jones|1967-12-01|\n",
            "|    Jen|      Mary|   Brown|1980-02-17|\n",
            "+-------+----------+--------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"year\", split(df['dob'],\"-\").getItem(0)) \\\n",
        ".withColumn(\"month\", split(df['dob'],'-').getItem(1)) \\\n",
        ".withColumn(\"day\", split(df['dob'],'-').getItem(2)).show()\n",
        " \n",
        "           "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGH0fJ99kH7Z",
        "outputId": "abe1b68d-9218-4889-b6be-ce8aa7d4cd15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+--------+----------+----+-----+---+\n",
            "|   name|middlename|lastname|       dob|year|month|day|\n",
            "+-------+----------+--------+----------+----+-----+---+\n",
            "|  James|          |   Smith|1991-04-01|1991|   04| 01|\n",
            "|Michael|      Rose|        |2000-05-19|2000|   05| 19|\n",
            "| Robert|          |Williams|1978-09-05|1978|   09| 05|\n",
            "|  Maria|      Anne|   Jones|1967-12-01|1967|   12| 01|\n",
            "|    Jen|      Mary|   Brown|1980-02-17|1980|   02| 17|\n",
            "+-------+----------+--------+----------+----+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_data=[\n",
        "           [\"2022/03/31 01:55 AM\"],\n",
        "           [\"2022/03/30 01:15 AM\"],\n",
        "           [\"2022/03/29 02:15 PM\"],\n",
        "           [\"2022/04/01 04:15 PM\"],\n",
        "          ]\n",
        "\n",
        "list_schema=[\"inp_col\"]\n",
        "\n",
        "#Create DataFrame from the list \n",
        "df1=spark.createDataFrame(list_data,list_schema)\n",
        "\n",
        "df1.printSchema()\n",
        "\n",
        "df1.show()"
      ],
      "metadata": {
        "id": "WmhgDcPaHSgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")"
      ],
      "metadata": {
        "id": "ZN-GvAE_HYL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_date,date_format,to_timestamp\n",
        "\n",
        "df2 = df1.withColumn(\"date\",to_date(\"inp_col\",\"yyyy/MM/dd\")) \\\n",
        "         .withColumn(\"time\",to_timestamp(\"inp_col\",\"yyyy/MM/dd hh:mm a\")) \\\n",
        "      \n",
        "\n",
        "\n",
        "df2.printSchema()\n",
        "df2.display()"
      ],
      "metadata": {
        "id": "jyHkR_wdo934"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "pntpNWoTjLcn"
      }
    }
  ]
}